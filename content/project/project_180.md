{
  "Title": "Using Explainable Artificial Intelligence (XAI) to create a real-time closed-loop stimulation",
  "link_to_issue": "https://github.com/brainhackorg/global2021/issues/180",
  "issue_number": 180,
  "labels": [
    {
      "name": "git_skills:0_none",
      "description": "",
      "color": "bfdadc"
    },
    {
      "name": "programming:documentation",
      "description": "Markdown, Sphinx",
      "color": "5319e7"
    },
    {
      "name": "project_type:pipeline_development",
      "description": "",
      "color": "c5def5"
    },
    {
      "name": "topic:data_visualisation",
      "description": "",
      "color": "006b75"
    },
    {
      "name": "project",
      "description": "",
      "color": "f9bc70"
    },
    {
      "name": "status:web_ready",
      "description": "",
      "color": "0e8a16"
    },
    {
      "name": "project_development_status:0_concept_no_content",
      "description": "",
      "color": "bfd4f2"
    },
    {
      "name": "programming:Python",
      "description": "",
      "color": "5319e7"
    },
    {
      "name": "project_type:documentation",
      "description": "",
      "color": "c5def5"
    },
    {
      "name": "modality:EEG",
      "description": "",
      "color": "1d76db"
    },
    {
      "name": "modality:MRI",
      "description": "",
      "color": "1d76db"
    },
    {
      "name": "modality:behavioral",
      "description": "",
      "color": "1d76db"
    },
    {
      "name": "modality:fMRI",
      "description": "",
      "color": "1d76db"
    },
    {
      "name": "project_type:visualisation",
      "description": "",
      "color": "c5def5"
    },
    {
      "name": "bhg:toronto_can_1",
      "description": "BHG 2021 Toronto event",
      "color": "d4c5f9"
    }
  ],
  "content": "### Title\r\n\r\nUsing Explainable Artificial Intelligence (XAI) to create a real-time closed-loop stimulation\r\n\r\n### Leaders\r\n\r\nSyed Hussain Ather (Twitter: @SHussainAther) \r\n\r\n### Collaborators\r\n\r\n_No response_\r\n\r\n### Brainhack Global 2021 Event\r\n\r\nBrainHack Toronto\r\n\r\n### Project Description\r\n\r\n- What are you doing, for whom, and why?\r\n\r\nLike similar work in other fields (e.g., computer vision, ML, etc.) on established datasets, we propose a project to create a pipeline explainable artificial intelligence (XAI) on a neurostimulation experimental and theoretical procedure. Given input recording of brain signals from some source (EEG data most likely), there's research geared toward using existing or novel XAI techniques to a known neurostimulation paradigm to provide explanatory power to close-loop neurobehavioral modulation (e.g., counter-factual probes). We hope this can be a step toward more innovative future work in creating a real time, closed-loop stimulation for deep brain stimulation (DBS). We hope to use this pipeline in improving research that can be used to modulate neural activity in real time. These types of frameworks can be used to advance work in intelligent computational approaches able to sense, interpret, and modulate a large amount of data from behaviorally relevant neural circuits at the speed of thoughts.\r\n\r\n- What makes your project special and exciting?\r\n\r\nThe use of Artificial Intelligence and machine learning in basic research and clinical neuroscience is increasing. AI methods enable the interpretation of large multimodal datasets that can provide unbiased insights into the fundamental principles of brain function, potentially paving the way for earlier and more accurate detection of brain disorders and better-informed intervention protocols. Despite AI\u2019s ability to create accurate predictions and classifications, in most cases, it lacks the ability to provide a mechanistic understanding of how inputs and outputs relate to each other. Explainable Artificial Intelligence (XAI) is a new set of techniques that attempts to provide such an understanding, here we report on some of these practical approaches.\r\n\r\n- How to get started?\r\n\r\nUsing one of these GUI tools (https://github.com/anguyen8/XAI-papers, most likely DeepVis), we hope to create a functioning pipeline that provides this explanatory power. Create a working model just like Figure 2. (https://www.frontiersin.org/files/Articles/490966/fnins-13-01346-HTML-r1/image_m/fnins-13-01346-g002.jpg)\r\n \r\n- Where to find key resources?\r\n\r\nInstall them as required by Deep Visualization (https://github.com/yosinski/deep-visualization-toolbox) there are\r\n\r\n### Link to project repository/sources\r\n\r\nhttps://github.com/HussainAther/XAI\r\n\r\n### Goals for Brainhack Global\r\n\r\n**Goal**: Create a functional, working pipeline that follows the three steps (pre-modelling, modelling, and post-modelling steps) from Figure 2 of Fellous et al., (https://www.frontiersin.org/files/Articles/490966/fnins-13-01346-HTML-r1/image_m/fnins-13-01346-g002.jpg) \r\n\r\n- - [ ] Pre-modelling: Characterize input data\r\n- - - [ ] \r\n- - - [ ] \r\n- - [ ] Modelling: Design explainable modelling architectures\r\n- - - [ ] \r\n- - - [ ] \r\n- - [ ] Post-modelling: Extract explanations from output\r\n- - - [ ] \r\n- - - [ ] \r\n\r\n### Good first issues\r\n\r\n1. Issue one: \r\n\r\n2. issue two:\r\n\r\n\r\n### Communication channels\r\n\r\nhttps://mattermost.brainhack.org/brainhack/channels/brainhack-toronto\r\n\r\n### Skills\r\n\r\n- Python: intermediate\r\n- Git: intermediate\r\n\r\n### Onboarding documentation\r\n\r\n_No response_\r\n\r\n### What will participants learn?\r\n\r\nI imagine that, at Brainhack 2021, like other or previous Brainhacks, we all learn skills in collaboration, organization, communication, team and project management, and other areas that can benefit any researcher interested in AI or similar fields related to programming and data. \r\n\r\n### Data to use\r\n\r\n_No response_\r\n\r\n### Number of collaborators\r\n\r\n3\r\n\r\n### Credit to collaborators\r\n\r\nProject contributors are listed on the project README using [all-contributors github bot](https://github.com/all-contributors/all-contributors).\r\n\r\n### Image\r\n\r\nLeave this text if you don't have an image yet.\r\n\r\n### Type\r\n\r\npipeline_development\r\n\r\n### Development status\r\n\r\n0_concept_no_content\r\n\r\n### Topic\r\n\r\ndata_visualisation\r\n\r\n### Tools\r\n\r\nother\r\n\r\n### Programming language\r\n\r\nPython\r\n\r\n### Modalities\r\n\r\nfMRI\r\n\r\n### Git skills\r\n\r\n0_no_git_skills\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Things to do after the project is submitted and ready to review.\r\n\r\n- [X] Add a comment below the main post of your issue saying: `Hi @brainhackorg/project-monitors my project is ready!`\r\n- [ ] Twitter-sized summary of your project pitch.",
  "project_url": "https://github.com/HussainAther/XAI",
  "project_description": "\r\n\r\n- What are you doing, for whom, and why?\r\n\r\nLike similar work in other fields (e.g., computer vision, ML, etc.) on established datasets, we propose a project to create a pipeline explainable artificial intelligence (XAI) on a neurostimulation experimental and theoretical procedure. Given input recording of brain signals from some source (EEG data most likely), there's research geared toward using existing or novel XAI techniques to a known neurostimulation paradigm to provide explanatory power to close-loop neurobehavioral modulation (e.g., counter-factual probes). We hope this can be a step toward more innovative future work in creating a real time, closed-loop stimulation for deep brain stimulation (DBS). We hope to use this pipeline in improving research that can be used to modulate neural activity in real time. These types of frameworks can be used to advance work in intelligent computational approaches able to sense, interpret, and modulate a large amount of data from behaviorally relevant neural circuits at the speed of thoughts.\r\n\r\n- What makes your project special and exciting?\r\n\r\nThe use of Artificial Intelligence and machine learning in basic research and clinical neuroscience is increasing. AI methods enable the interpretation of large multimodal datasets that can provide unbiased insights into the fundamental principles of brain function, potentially paving the way for earlier and more accurate detection of brain disorders and better-informed intervention protocols. Despite AI\u2019s ability to create accurate predictions and classifications, in most cases, it lacks the ability to provide a mechanistic understanding of how inputs and outputs relate to each other. Explainable Artificial Intelligence (XAI) is a new set of techniques that attempts to provide such an understanding, here we report on some of these practical approaches.\r\n\r\n- How to get started?\r\n\r\nUsing one of these GUI tools (https://github.com/anguyen8/XAI-papers, most likely DeepVis), we hope to create a functioning pipeline that provides this explanatory power. Create a working model just like Figure 2. (https://www.frontiersin.org/files/Articles/490966/fnins-13-01346-HTML-r1/image_m/fnins-13-01346-g002.jpg)\r\n \r\n- Where to find key resources?\r\n\r\nInstall them as required by Deep Visualization (https://github.com/yosinski/deep-visualization-toolbox) there are\r\n\r\n"
}